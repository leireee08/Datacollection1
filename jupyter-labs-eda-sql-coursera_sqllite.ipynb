{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n",
    "\n",
    "<h1 align=center><font size = 5>Assignment: SQL Notebook for Peer Assignment</font></h1>\n",
    "\n",
    "Estimated time needed: **60** minutes.\n",
    "\n",
    "## Introduction\n",
    "Using this Python notebook you will:\n",
    "\n",
    "1.  Understand the Spacex DataSet\n",
    "2.  Load the dataset  into the corresponding table in a Db2 database\n",
    "3.  Execute SQL queries to answer assignment questions \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the DataSet\n",
    "\n",
    "SpaceX has gained worldwide attention for a series of historic milestones. \n",
    "\n",
    "It is the only private company ever to return a spacecraft from low-earth orbit, which it first accomplished in December 2010.\n",
    "SpaceX advertises Falcon 9 rocket launches on its website with a cost of 62 million dollars wheras other providers cost upward of 165 million dollars each, much of the savings is because Space X can reuse the first stage. \n",
    "\n",
    "\n",
    "Therefore if we can determine if the first stage will land, we can determine the cost of a launch. \n",
    "\n",
    "This information can be used if an alternate company wants to bid against SpaceX for a rocket launch.\n",
    "\n",
    "This dataset includes a record for each payload carried during a SpaceX mission into outer space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the datasets\n",
    "\n",
    "This assignment requires you to load the spacex dataset.\n",
    "\n",
    "In many cases the dataset to be analyzed is available as a .CSV (comma separated values) file, perhaps on the internet. Click on the link below to download and save the dataset (.CSV file):\n",
    "\n",
    " <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/data/Spacex.csv\" target=\"_blank\">Spacex DataSet</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sqlalchemy==1.3.9\n",
      "  Downloading SQLAlchemy-1.3.9.tar.gz (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "  Preparing metadata (setup.py) ... \u001b[?2done\n",
      "\u001b[?25hBuilding wheels for collected packages: sqlalchemy\n",
      "  Building wheel for sqlalchemy (setup.py) ...done\n",
      "\u001b[?25h  Created wheel for sqlalchemy: filename=SQLAlchemy-1.3.9-cp312-cp312-linux_x86_64.whl size=1160111 sha256=e12dd507ad4860eb21daaa9a73859442a302631e0b437a750f1c4a4683302e9c\n",
      "  Stored in directory: /home/jupyterlab/.cache/pip/wheels/b3/1c/42/0e26b8d512adc6bce10ff71a05229366b4ccec641cd3b42111\n",
      "Successfully built sqlalchemy\n",
      "Installing collected packages: sqlalchemy\n",
      "  Attempting uninstall: sqlalchemy\n",
      "    Found existing installation: SQLAlchemy 2.0.37\n",
      "    Uninstalling SQLAlchemy-2.0.37:\n",
      "      Successfully uninstalled SQLAlchemy-2.0.37\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyterhub 5.2.1 requires SQLAlchemy>=1.4.1, but you have sqlalchemy 1.3.9 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed sqlalchemy-1.3.9\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlalchemy==1.3.9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the database\n",
    "\n",
    "Let us first load the SQL extension and establish a connection with the database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipython-sql\n",
      "  Downloading ipython_sql-0.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting prettytable (from ipython-sql)\n",
      "  Downloading prettytable-3.17.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: ipython in /opt/conda/lib/python3.12/site-packages (from ipython-sql) (8.31.0)\n",
      "Collecting sqlalchemy>=2.0 (from ipython-sql)\n",
      "  Downloading sqlalchemy-2.0.46-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting sqlparse (from ipython-sql)\n",
      "  Downloading sqlparse-0.5.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.12/site-packages (from ipython-sql) (1.17.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.12/site-packages (from ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: greenlet>=1 in /opt/conda/lib/python3.12/site-packages (from sqlalchemy>=2.0->ipython-sql) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.12/site-packages (from sqlalchemy>=2.0->ipython-sql) (4.12.2)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.12/site-packages (from prettytable->ipython-sql) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/conda/lib/python3.12/site-packages (from jedi>=0.16->ipython->ipython-sql) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.12/site-packages (from pexpect>4.3->ipython->ipython-sql) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython->ipython-sql) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython->ipython-sql) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython->ipython-sql) (0.2.3)\n",
      "Downloading ipython_sql-0.5.0-py3-none-any.whl (20 kB)\n",
      "Downloading sqlalchemy-2.0.46-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading prettytable-3.17.0-py3-none-any.whl (34 kB)\n",
      "Downloading sqlparse-0.5.5-py3-none-any.whl (46 kB)\n",
      "Installing collected packages: sqlparse, sqlalchemy, prettytable, ipython-sql\n",
      "  Attempting uninstall: sqlalchemy\n",
      "    Found existing installation: SQLAlchemy 1.3.9\n",
      "    Uninstalling SQLAlchemy-1.3.9:\n",
      "      Successfully uninstalled SQLAlchemy-1.3.9\n",
      "Successfully installed ipython-sql-0.5.0 prettytable-3.17.0 sqlalchemy-2.0.46 sqlparse-0.5.5\n",
      "Requirement already satisfied: ipython-sql in /opt/conda/lib/python3.12/site-packages (0.5.0)\n",
      "Requirement already satisfied: prettytable in /opt/conda/lib/python3.12/site-packages (3.17.0)\n",
      "Requirement already satisfied: ipython in /opt/conda/lib/python3.12/site-packages (from ipython-sql) (8.31.0)\n",
      "Requirement already satisfied: sqlalchemy>=2.0 in /opt/conda/lib/python3.12/site-packages (from ipython-sql) (2.0.46)\n",
      "Requirement already satisfied: sqlparse in /opt/conda/lib/python3.12/site-packages (from ipython-sql) (0.5.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.12/site-packages (from ipython-sql) (1.17.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.12/site-packages (from ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.12/site-packages (from prettytable) (0.2.13)\n",
      "Requirement already satisfied: greenlet>=1 in /opt/conda/lib/python3.12/site-packages (from sqlalchemy>=2.0->ipython-sql) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.12/site-packages (from sqlalchemy>=2.0->ipython-sql) (4.12.2)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /opt/conda/lib/python3.12/site-packages (from ipython->ipython-sql) (5.14.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/conda/lib/python3.12/site-packages (from jedi>=0.16->ipython->ipython-sql) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.12/site-packages (from pexpect>4.3->ipython->ipython-sql) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython->ipython-sql) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython->ipython-sql) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython->ipython-sql) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipython-sql\n",
    "!pip install ipython-sql prettytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, sqlite3\n",
    "import prettytable\n",
    "prettytable.DEFAULT = 'DEFAULT'\n",
    "\n",
    "con = sqlite3.connect(\"my_data1.db\")\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql sqlite:///my_data1.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/data/Spacex.csv\")\n",
    "df.to_sql(\"SPACEXTBL\", con, if_exists='replace', index=False,method=\"multi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:This below code is added to remove blank rows from table**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///my_data1.db\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DROP THE TABLE IF EXISTS\n",
    "\n",
    "%sql DROP TABLE IF EXISTS SPACEXTABLE;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///my_data1.db\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql create table SPACEXTABLE as select * from SPACEXTBL where Date is not null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "Now write and execute SQL queries to solve the assignment tasks.\n",
    "\n",
    "**Note: If the column names are in mixed case enclose it in double quotes\n",
    "   For Example \"Landing_Outcome\"**\n",
    "\n",
    "### Task 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### Display the names of the unique launch sites  in the space mission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///my_data1.db\n",
      "(sqlite3.OperationalError) no such table: space_mission\n",
      "[SQL: SELECT DISTINCT \"Launch_Site\" \n",
      "FROM space_mission \n",
      "WHERE \"Launch_Site\" IS NOT NULL \n",
      "ORDER BY \"Launch_Site\";]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT DISTINCT \"Launch_Site\" \n",
    "FROM space_mission \n",
    "WHERE \"Launch_Site\" IS NOT NULL \n",
    "ORDER BY \"Launch_Site\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in the database:\n",
      "          name\n",
      "0    SPACEXTBL\n",
      "1  SPACEXTABLE\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('my_data1.db')\n",
    "\n",
    "# Get list of all tables\n",
    "query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "tables = pd.read_sql_query(query, conn)\n",
    "print(\"Tables in the database:\")\n",
    "print(tables)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 unique launch sites in SPACEXTBL:\n",
      "    Launch_Site\n",
      "0   CCAFS LC-40\n",
      "1  CCAFS SLC-40\n",
      "2    KSC LC-39A\n",
      "3   VAFB SLC-4E\n",
      "\n",
      "Full list:\n",
      "    Launch_Site\n",
      "0   CCAFS LC-40\n",
      "1  CCAFS SLC-40\n",
      "2    KSC LC-39A\n",
      "3   VAFB SLC-4E\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect('my_data1.db')\n",
    "\n",
    "# Option 1: Try SPACEXTBL first\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT \"Launch_Site\" \n",
    "FROM SPACEXTBL \n",
    "WHERE \"Launch_Site\" IS NOT NULL \n",
    "ORDER BY \"Launch_Site\";\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    print(f\"Found {len(df)} unique launch sites in SPACEXTBL:\")\n",
    "    print(df.head())\n",
    "    print(\"\\nFull list:\")\n",
    "    print(df)\n",
    "except Exception as e:\n",
    "    print(f\"Error with SPACEXTBL: {e}\")\n",
    "    \n",
    "    # Option 2: Try SPACEXTABLE\n",
    "    query = \"\"\"\n",
    "    SELECT DISTINCT \"Launch_Site\" \n",
    "    FROM SPACEXTABLE \n",
    "    WHERE \"Launch_Site\" IS NOT NULL \n",
    "    ORDER BY \"Launch_Site\";\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        print(f\"\\nFound {len(df)} unique launch sites in SPACEXTABLE:\")\n",
    "        print(df.head())\n",
    "        print(\"\\nFull list:\")\n",
    "        print(df)\n",
    "    except Exception as e2:\n",
    "        print(f\"Error with SPACEXTABLE: {e2}\")\n",
    "        \n",
    "        # Let's find the correct column name\n",
    "        print(\"\\n=== Let's find the right column ===\")\n",
    "        for table in ['SPACEXTBL', 'SPACEXTABLE']:\n",
    "            print(f\"\\nColumns in {table}:\")\n",
    "            columns_df = pd.read_sql_query(f\"PRAGMA table_info({table});\", conn)\n",
    "            print(columns_df[['name', 'type']])\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Task 2\n",
    "\n",
    "\n",
    "#####  Display 5 records where launch sites begin with the string 'CCA' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 records where Launch_Site begins with 'CCA':\n",
      "         Date Time (UTC) Booster_Version  Launch_Site  \\\n",
      "0  2010-06-04   18:45:00  F9 v1.0  B0003  CCAFS LC-40   \n",
      "1  2010-12-08   15:43:00  F9 v1.0  B0004  CCAFS LC-40   \n",
      "2  2012-05-22    7:44:00  F9 v1.0  B0005  CCAFS LC-40   \n",
      "3  2012-10-08    0:35:00  F9 v1.0  B0006  CCAFS LC-40   \n",
      "4  2013-03-01   15:10:00  F9 v1.0  B0007  CCAFS LC-40   \n",
      "\n",
      "                                             Payload  PAYLOAD_MASS__KG_  \\\n",
      "0               Dragon Spacecraft Qualification Unit                  0   \n",
      "1  Dragon demo flight C1, two CubeSats, barrel of...                  0   \n",
      "2                              Dragon demo flight C2                525   \n",
      "3                                       SpaceX CRS-1                500   \n",
      "4                                       SpaceX CRS-2                677   \n",
      "\n",
      "       Orbit         Customer Mission_Outcome      Landing_Outcome  \n",
      "0        LEO           SpaceX         Success  Failure (parachute)  \n",
      "1  LEO (ISS)  NASA (COTS) NRO         Success  Failure (parachute)  \n",
      "2  LEO (ISS)      NASA (COTS)         Success           No attempt  \n",
      "3  LEO (ISS)       NASA (CRS)         Success           No attempt  \n",
      "4  LEO (ISS)       NASA (CRS)         Success           No attempt  \n",
      "\n",
      "Detailed view:\n",
      "         Date Time (UTC) Booster_Version  Launch_Site  \\\n",
      "0  2010-06-04   18:45:00  F9 v1.0  B0003  CCAFS LC-40   \n",
      "1  2010-12-08   15:43:00  F9 v1.0  B0004  CCAFS LC-40   \n",
      "2  2012-05-22    7:44:00  F9 v1.0  B0005  CCAFS LC-40   \n",
      "3  2012-10-08    0:35:00  F9 v1.0  B0006  CCAFS LC-40   \n",
      "4  2013-03-01   15:10:00  F9 v1.0  B0007  CCAFS LC-40   \n",
      "\n",
      "                                             Payload  PAYLOAD_MASS__KG_  \\\n",
      "0               Dragon Spacecraft Qualification Unit                  0   \n",
      "1  Dragon demo flight C1, two CubeSats, barrel of...                  0   \n",
      "2                              Dragon demo flight C2                525   \n",
      "3                                       SpaceX CRS-1                500   \n",
      "4                                       SpaceX CRS-2                677   \n",
      "\n",
      "       Orbit         Customer Mission_Outcome      Landing_Outcome  \n",
      "0        LEO           SpaceX         Success  Failure (parachute)  \n",
      "1  LEO (ISS)  NASA (COTS) NRO         Success  Failure (parachute)  \n",
      "2  LEO (ISS)      NASA (COTS)         Success           No attempt  \n",
      "3  LEO (ISS)       NASA (CRS)         Success           No attempt  \n",
      "4  LEO (ISS)       NASA (CRS)         Success           No attempt  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "conn = sqlite3.connect('my_data1.db')\n",
    "\n",
    "# Task 2: Display 5 records where launch sites begin with 'CCA'\n",
    "query = \"\"\"\n",
    "SELECT * \n",
    "FROM SPACEXTBL \n",
    "WHERE \"Launch_Site\" LIKE 'CCA%' \n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query, conn)\n",
    "print(f\"Found {len(df)} records where Launch_Site begins with 'CCA':\")\n",
    "print(df)\n",
    "\n",
    "# Show all columns clearly\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "print(\"\\nDetailed view:\")\n",
    "print(df)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### Display the total payload mass carried by boosters launched by NASA (CRS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Checking table structure ===\n",
      "             name    type\n",
      "             Date    TEXT\n",
      "       Time (UTC)    TEXT\n",
      "  Booster_Version    TEXT\n",
      "      Launch_Site    TEXT\n",
      "          Payload    TEXT\n",
      "PAYLOAD_MASS__KG_ INTEGER\n",
      "            Orbit    TEXT\n",
      "         Customer    TEXT\n",
      "  Mission_Outcome    TEXT\n",
      "  Landing_Outcome    TEXT\n",
      "\n",
      "=== Checking for NASA/CRS related data ===\n",
      "Unique values in possible mission/customer columns:\n",
      "\n",
      "Column: Customer\n",
      "                Customer\n",
      "                  SpaceX\n",
      "         NASA (COTS) NRO\n",
      "             NASA (COTS)\n",
      "              NASA (CRS)\n",
      "                     MDA\n",
      "                     SES\n",
      "                 Thaicom\n",
      "                 Orbcomm\n",
      "                 AsiaSat\n",
      "U.S. Air Force NASA NOAA\n",
      "\n",
      "Column: Orbit\n",
      "      Orbit\n",
      "        LEO\n",
      "  LEO (ISS)\n",
      "  Polar LEO\n",
      "        GTO\n",
      "        HEO\n",
      "        SSO\n",
      "        MEO\n",
      "Sub-orbital\n",
      "\n",
      "Column: Launch_Site\n",
      " Launch_Site\n",
      " CCAFS LC-40\n",
      " VAFB SLC-4E\n",
      "  KSC LC-39A\n",
      "CCAFS SLC-40\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('my_data1.db')\n",
    "\n",
    "# First, let's check what columns are available in the table\n",
    "print(\"=== Checking table structure ===\")\n",
    "columns_query = \"PRAGMA table_info(SPACEXTBL);\"\n",
    "columns_df = pd.read_sql_query(columns_query, conn)\n",
    "print(columns_df[['name', 'type']].to_string(index=False))\n",
    "\n",
    "# Based on the column names, let's look for relevant columns\n",
    "print(\"\\n=== Checking for NASA/CRS related data ===\")\n",
    "print(\"Unique values in possible mission/customer columns:\")\n",
    "\n",
    "# Check for columns that might contain NASA/CRS information\n",
    "possible_cols = ['Customer', 'Mission', 'Orbit', 'Launch_Site']\n",
    "for col in possible_cols:\n",
    "    if col in columns_df['name'].values:\n",
    "        query = f'SELECT DISTINCT \"{col}\" FROM SPACEXTBL WHERE \"{col}\" IS NOT NULL LIMIT 10;'\n",
    "        try:\n",
    "            sample = pd.read_sql_query(query, conn)\n",
    "            print(f\"\\nColumn: {col}\")\n",
    "            print(sample.head(10).to_string(index=False))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### Display average payload mass carried by booster version F9 v1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average payload mass by booster version:\n",
      "Booster_Version  Average_Payload_Mass  Mission_Count\n",
      "  F9 v1.1 B1018                   0.0              1\n",
      "  F9 v1.1 B1017                   0.0              1\n",
      "  F9 v1.1 B1016                   0.0              1\n",
      "  F9 v1.1 B1015                   0.0              1\n",
      "  F9 v1.1 B1014                   0.0              1\n",
      "  F9 v1.1 B1013                   0.0              1\n",
      "  F9 v1.1 B1012                   0.0              1\n",
      "  F9 v1.1 B1011                   0.0              1\n",
      "  F9 v1.1 B1010                   0.0              1\n",
      " F9 v1.1  B1003                   0.0              1\n",
      "        F9 v1.1                   0.0              5\n",
      " F9 v1.0  B0007                   0.0              1\n",
      " F9 v1.0  B0006                   0.0              1\n",
      " F9 v1.0  B0005                   0.0              1\n",
      " F9 v1.0  B0004                   0.0              1\n",
      " F9 v1.0  B0003                   0.0              1\n",
      "  F9 FT B1038.1                   0.0              1\n",
      "    F9 FT B1037                   0.0              1\n",
      "  F9 FT B1036.1                   0.0              1\n",
      "  F9 FT B1035.1                   0.0              1\n",
      "    F9 FT B1034                   0.0              1\n",
      "  F9 FT B1032.1                   0.0              1\n",
      "  F9 FT B1031.1                   0.0              1\n",
      "    F9 FT B1030                   0.0              1\n",
      "  F9 FT B1029.1                   0.0              1\n",
      "    F9 FT B1026                   0.0              1\n",
      "  F9 FT B1025.1                   0.0              1\n",
      "    F9 FT B1024                   0.0              1\n",
      "  F9 FT B1023.1                   0.0              1\n",
      "    F9 FT B1022                   0.0              1\n",
      "  F9 FT B1021.1                   0.0              1\n",
      "    F9 FT B1020                   0.0              1\n",
      "    F9 FT B1019                   0.0              1\n",
      " F9 FT  B1038.2                   0.0              1\n",
      " F9 FT  B1036.2                   0.0              1\n",
      " F9 FT  B1035.2                   0.0              1\n",
      " F9 FT  B1032.2                   0.0              1\n",
      " F9 FT  B1031.2                   0.0              1\n",
      " F9 FT  B1029.2                   0.0              1\n",
      " F9 FT  B1021.2                   0.0              1\n",
      "   F9 B5B1063.1                   0.0              1\n",
      "   F9 B5B1062.1                   0.0              1\n",
      "  F9 B5B1061.1                    0.0              1\n",
      "   F9 B5B1060.1                   0.0              1\n",
      "   F9 B5B1059.1                   0.0              1\n",
      "  F9 B5B1058.1                    0.0              1\n",
      "  F9 B5B1056.1                    0.0              1\n",
      "     F9 B5B1054                   0.0              1\n",
      "   F9 B5B1051.1                   0.0              1\n",
      "     F9 B5B1050                   0.0              1\n",
      "   F9 B5B1049.1                   0.0              1\n",
      "   F9 B5B1048.1                   0.0              1\n",
      "   F9 B5B1047.1                   0.0              1\n",
      "  F9 B5 B1060.3                   0.0              1\n",
      " F9 B5 B1060.2                    0.0              1\n",
      "  F9 B5 B1059.4                   0.0              1\n",
      "  F9 B5 B1059.3                   0.0              1\n",
      "  F9 B5 B1059.2                   0.0              1\n",
      " F9 B5 B1058.4                    0.0              1\n",
      " F9 B5 B1058.3                    0.0              1\n",
      " F9 B5 B1058.2                    0.0              1\n",
      "  F9 B5 B1056.4                   0.0              1\n",
      " F9 B5 B1056.3                    0.0              1\n",
      " F9 B5 B1056.2                    0.0              1\n",
      "  F9 B5 B1051.6                   0.0              1\n",
      "  F9 B5 B1051.5                   0.0              1\n",
      "  F9 B5 B1051.4                   0.0              1\n",
      "  F9 B5 B1051.3                   0.0              1\n",
      " F9 B5 B1051.2                    0.0              1\n",
      " F9 B5 B1049.7                    0.0              1\n",
      "  F9 B5 B1049.6                   0.0              1\n",
      "  F9 B5 B1049.5                   0.0              1\n",
      "  F9 B5 B1049.4                   0.0              1\n",
      "  F9 B5 B1049.3                   0.0              1\n",
      "  F9 B5 B1049.2                   0.0              1\n",
      "  F9 B5 B1048.5                   0.0              1\n",
      "  F9 B5 B1048.4                   0.0              1\n",
      "  F9 B5 B1048.3                   0.0              1\n",
      "  F9 B5 B1048.2                   0.0              1\n",
      " F9 B5 B1047.3                    0.0              1\n",
      "  F9 B5 B1047.2                   0.0              1\n",
      "  F9 B5 B1046.4                   0.0              1\n",
      "  F9 B5 B1046.3                   0.0              1\n",
      "  F9 B5 B1046.2                   0.0              1\n",
      " F9 B5  B1046.1                   0.0              1\n",
      "  F9 B4 B1045.2                   0.0              1\n",
      "  F9 B4 B1045.1                   0.0              1\n",
      "    F9 B4 B1044                   0.0              1\n",
      "  F9 B4 B1043.1                   0.0              1\n",
      "  F9 B4 B1042.1                   0.0              1\n",
      "  F9 B4 B1041.1                   0.0              1\n",
      "  F9 B4 B1040.1                   0.0              1\n",
      "  F9 B4 B1039.1                   0.0              1\n",
      " F9 B4  B1043.2                   0.0              1\n",
      " F9 B4  B1041.2                   0.0              1\n",
      " F9 B4  B1040.2                   0.0              1\n",
      " F9 B4  B1039.2                   0.0              1\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('my_data1.db')\n",
    "\n",
    "# Compare all booster versions\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    \"Booster_Version\",\n",
    "    AVG(\"Payload_Mass\") as \"Average_Payload_Mass\",\n",
    "    COUNT(*) as \"Mission_Count\"\n",
    "FROM SPACEXTBL \n",
    "WHERE \"Booster_Version\" IS NOT NULL\n",
    "GROUP BY \"Booster_Version\"\n",
    "ORDER BY \"Average_Payload_Mass\" DESC;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query, conn)\n",
    "print(\"Average payload mass by booster version:\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "\n",
    "##### List the date when the first succesful landing outcome in ground pad was acheived.\n",
    "\n",
    "\n",
    "_Hint:Use min function_ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First successful ground pad landing:\n",
      "First_Successful_Ground_Pad_Landing_Date      Landing_Outcome Booster_Version Launch_Site\n",
      "                              2015-12-22 Success (ground pad)     F9 FT B1019 CCAFS LC-40\n",
      "\n",
      "The first successful ground pad landing was on: 2015-12-22\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('my_data1.db')\n",
    "\n",
    "# Task: Find the date of first successful ground pad landing\n",
    "# We need to look for successful ground pad outcomes and find the earliest date\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    MIN(\"Date\") as \"First_Successful_Ground_Pad_Landing_Date\",\n",
    "    \"Landing_Outcome\",\n",
    "    \"Booster_Version\",\n",
    "    \"Launch_Site\"\n",
    "FROM SPACEXTBL \n",
    "WHERE (\"Landing_Outcome\" LIKE '%Success%' AND \n",
    "       (\"Landing_Outcome\" LIKE '%ground%' OR \"Landing_Outcome\" LIKE '%pad%'))\n",
    "   OR \"Landing_Outcome\" = 'Success (ground pad)'\n",
    "   OR \"Landing_Outcome\" = 'Success (ground pad).'\n",
    "GROUP BY \"Landing_Outcome\"\n",
    "ORDER BY \"Date\" ASC\n",
    "LIMIT 1;\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    print(\"First successful ground pad landing:\")\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    if not df.empty:\n",
    "        print(f\"\\nThe first successful ground pad landing was on: {df['First_Successful_Ground_Pad_Landing_Date'].iloc[0]}\")\n",
    "    else:\n",
    "        print(\"No successful ground pad landings found with those criteria\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6\n",
    "\n",
    "##### List the names of the boosters which have success in drone ship and have payload mass greater than 4000 but less than 6000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boosters with successful drone ship landings and payload mass 4000-6000:\n",
      "Booster_Version \"Payload_Mass\"        Landing_Outcome       Date  Launch_Site\n",
      "  F9 B4 B1041.1   Payload_Mass   Success (drone ship) 2017-10-09  VAFB SLC-4E\n",
      "  F9 B4 B1042.1   Payload_Mass   Success (drone ship) 2017-10-30   KSC LC-39A\n",
      "  F9 B4 B1045.1   Payload_Mass   Success (drone ship) 2018-04-18 CCAFS SLC-40\n",
      " F9 B5  B1046.1   Payload_Mass   Success (drone ship) 2018-05-11   KSC LC-39A\n",
      " F9 FT  B1021.2   Payload_Mass   Success (drone ship) 2017-03-30   KSC LC-39A\n",
      " F9 FT  B1029.2   Payload_Mass   Success (drone ship) 2017-06-23   KSC LC-39A\n",
      " F9 FT  B1031.2   Payload_Mass   Success (drone ship) 2017-10-11   KSC LC-39A\n",
      "    F9 FT B1020   Payload_Mass   Failure (drone ship) 2016-03-04  CCAFS LC-40\n",
      "  F9 FT B1021.1   Payload_Mass   Success (drone ship) 2016-04-08  CCAFS LC-40\n",
      "    F9 FT B1022   Payload_Mass   Success (drone ship) 2016-05-06  CCAFS LC-40\n",
      "  F9 FT B1023.1   Payload_Mass   Success (drone ship) 2016-05-27  CCAFS LC-40\n",
      "    F9 FT B1024   Payload_Mass   Failure (drone ship) 2016-06-15  CCAFS LC-40\n",
      "    F9 FT B1026   Payload_Mass   Success (drone ship) 2016-08-14  CCAFS LC-40\n",
      "  F9 FT B1029.1   Payload_Mass   Success (drone ship) 2017-01-14  VAFB SLC-4E\n",
      "  F9 FT B1036.1   Payload_Mass   Success (drone ship) 2017-06-25  VAFB SLC-4E\n",
      "  F9 FT B1038.1   Payload_Mass   Success (drone ship) 2017-08-24  VAFB SLC-4E\n",
      "  F9 v1.1 B1012   Payload_Mass   Failure (drone ship) 2015-01-10  CCAFS LC-40\n",
      "  F9 v1.1 B1015   Payload_Mass   Failure (drone ship) 2015-04-14  CCAFS LC-40\n",
      "  F9 v1.1 B1017   Payload_Mass   Failure (drone ship) 2016-01-17  VAFB SLC-4E\n",
      "  F9 v1.1 B1018   Payload_Mass Precluded (drone ship) 2015-06-28  CCAFS LC-40\n",
      "\n",
      "Total unique boosters found: 20\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('my_data1.db')\n",
    "\n",
    "# Task 6: List boosters with success in drone ship AND payload mass > 4000 AND < 6000\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT \n",
    "    \"Booster_Version\",\n",
    "    \"Payload_Mass\",\n",
    "    \"Landing_Outcome\",\n",
    "    \"Date\",\n",
    "    \"Launch_Site\"\n",
    "FROM SPACEXTBL \n",
    "WHERE \"Landing_Outcome\" LIKE '%Success%drone%'\n",
    "   OR \"Landing_Outcome\" LIKE '%drone%Success%'\n",
    "   OR \"Landing_Outcome\" LIKE '%drone ship%'\n",
    "   OR \"Landing_Outcome\" = 'Success (drone ship)'\n",
    "   OR \"Landing_Outcome\" = 'Success (drone ship).'\n",
    "   AND \"Payload_Mass\" > 4000 \n",
    "   AND \"Payload_Mass\" < 6000\n",
    "ORDER BY \"Booster_Version\", \"Date\";\n",
    "\"\"\"\n",
    "\n",
    "print(\"Boosters with successful drone ship landings and payload mass 4000-6000:\")\n",
    "try:\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    if not df.empty:\n",
    "        print(df.to_string(index=False))\n",
    "        print(f\"\\nTotal unique boosters found: {df['Booster_Version'].nunique()}\")\n",
    "    else:\n",
    "        print(\"No records found with exact criteria\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### List the total number of successful and failure mission outcomes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 7: Total number of successful and failure mission outcomes\n",
      "============================================================\n",
      "Mission_Outcome  Count\n",
      "        Success    100\n",
      "        Failure      1\n",
      "\n",
      "Additional Statistics:\n",
      "Total missions with outcomes: 101\n",
      "Success rate: 99.0%\n",
      "Failure rate: 1.0%\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('my_data1.db')\n",
    "\n",
    "# Direct answer for Task 7\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    'Success' as Mission_Outcome,\n",
    "    COUNT(*) as Count\n",
    "FROM SPACEXTBL \n",
    "WHERE UPPER(\"Mission_Outcome\") LIKE '%SUCCESS%'\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "    'Failure' as Mission_Outcome,\n",
    "    COUNT(*) as Count\n",
    "FROM SPACEXTBL \n",
    "WHERE UPPER(\"Mission_Outcome\") LIKE '%FAIL%';\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query, conn)\n",
    "print(\"Task 7: Total number of successful and failure mission outcomes\")\n",
    "print(\"=\" * 60)\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Calculate percentages\n",
    "total_missions_query = \"SELECT COUNT(*) as total FROM SPACEXTBL WHERE \\\"Mission_Outcome\\\" IS NOT NULL;\"\n",
    "total_df = pd.read_sql_query(total_missions_query, conn)\n",
    "total = total_df['total'].iloc[0]\n",
    "\n",
    "if total > 0:\n",
    "    success_count = df[df['Mission_Outcome'] == 'Success']['Count'].iloc[0]\n",
    "    failure_count = df[df['Mission_Outcome'] == 'Failure']['Count'].iloc[0]\n",
    "    \n",
    "    print(f\"\\nAdditional Statistics:\")\n",
    "    print(f\"Total missions with outcomes: {total}\")\n",
    "    print(f\"Success rate: {success_count/total*100:.1f}%\")\n",
    "    print(f\"Failure rate: {failure_count/total*100:.1f}%\")\n",
    "    \n",
    "    # Check for other outcomes\n",
    "    other_count = total - success_count - failure_count\n",
    "    if other_count > 0:\n",
    "        print(f\"Other outcomes: {other_count} ({other_count/total*100:.1f}%)\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8\n",
    "\n",
    "\n",
    "\n",
    "##### List all the booster_versions that have carried the maximum payload mass, using a subquery with a suitable aggregate function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Different approaches to solve Task 8 ===\n",
      "\n",
      "1. Using subquery in WHERE clause:\n",
      "Booster_Version\n",
      " F9 v1.0  B0003\n",
      " F9 v1.0  B0004\n",
      " F9 v1.0  B0005\n",
      " F9 v1.0  B0006\n",
      " F9 v1.0  B0007\n",
      " F9 v1.1  B1003\n",
      "        F9 v1.1\n",
      "  F9 v1.1 B1011\n",
      "  F9 v1.1 B1010\n",
      "  F9 v1.1 B1012\n",
      "  F9 v1.1 B1013\n",
      "  F9 v1.1 B1014\n",
      "  F9 v1.1 B1015\n",
      "  F9 v1.1 B1016\n",
      "  F9 v1.1 B1018\n",
      "    F9 FT B1019\n",
      "  F9 v1.1 B1017\n",
      "    F9 FT B1020\n",
      "  F9 FT B1021.1\n",
      "    F9 FT B1022\n",
      "  F9 FT B1023.1\n",
      "    F9 FT B1024\n",
      "  F9 FT B1025.1\n",
      "    F9 FT B1026\n",
      "  F9 FT B1029.1\n",
      "  F9 FT B1031.1\n",
      "    F9 FT B1030\n",
      " F9 FT  B1021.2\n",
      "  F9 FT B1032.1\n",
      "    F9 FT B1034\n",
      "  F9 FT B1035.1\n",
      " F9 FT  B1029.2\n",
      "  F9 FT B1036.1\n",
      "    F9 FT B1037\n",
      "  F9 B4 B1039.1\n",
      "  F9 FT B1038.1\n",
      "  F9 B4 B1040.1\n",
      "  F9 B4 B1041.1\n",
      " F9 FT  B1031.2\n",
      "  F9 B4 B1042.1\n",
      " F9 FT  B1035.2\n",
      " F9 FT  B1036.2\n",
      "  F9 B4 B1043.1\n",
      " F9 FT  B1032.2\n",
      " F9 FT  B1038.2\n",
      "    F9 B4 B1044\n",
      " F9 B4  B1041.2\n",
      " F9 B4  B1039.2\n",
      "  F9 B4 B1045.1\n",
      " F9 B5  B1046.1\n",
      " F9 B4  B1043.2\n",
      " F9 B4  B1040.2\n",
      "  F9 B4 B1045.2\n",
      "   F9 B5B1047.1\n",
      "   F9 B5B1048.1\n",
      "  F9 B5 B1046.2\n",
      "   F9 B5B1049.1\n",
      "  F9 B5 B1048.2\n",
      "  F9 B5 B1047.2\n",
      "  F9 B5 B1046.3\n",
      "     F9 B5B1050\n",
      "     F9 B5B1054\n",
      "  F9 B5 B1049.2\n",
      "  F9 B5 B1048.3\n",
      "   F9 B5B1051.1\n",
      "  F9 B5B1056.1 \n",
      "  F9 B5 B1049.3\n",
      " F9 B5 B1051.2 \n",
      " F9 B5 B1056.2 \n",
      " F9 B5 B1047.3 \n",
      "  F9 B5 B1048.4\n",
      "   F9 B5B1059.1\n",
      " F9 B5 B1056.3 \n",
      "  F9 B5 B1049.4\n",
      "  F9 B5 B1046.4\n",
      "  F9 B5 B1051.3\n",
      "  F9 B5 B1056.4\n",
      "  F9 B5 B1059.2\n",
      "  F9 B5 B1048.5\n",
      "  F9 B5 B1051.4\n",
      "  F9 B5B1058.1 \n",
      "  F9 B5 B1049.5\n",
      "  F9 B5 B1059.3\n",
      "   F9 B5B1060.1\n",
      " F9 B5 B1058.2 \n",
      "  F9 B5 B1051.5\n",
      "  F9 B5 B1049.6\n",
      "  F9 B5 B1059.4\n",
      " F9 B5 B1060.2 \n",
      " F9 B5 B1058.3 \n",
      "  F9 B5 B1051.6\n",
      "  F9 B5 B1060.3\n",
      "   F9 B5B1062.1\n",
      "  F9 B5B1061.1 \n",
      "   F9 B5B1063.1\n",
      " F9 B5 B1049.7 \n",
      " F9 B5 B1058.4 \n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('my_data1.db')\n",
    "\n",
    "print(\"=== Different approaches to solve Task 8 ===\")\n",
    "\n",
    "print(\"\\n1. Using subquery in WHERE clause:\")\n",
    "query1 = \"\"\"\n",
    "SELECT DISTINCT \"Booster_Version\"\n",
    "FROM SPACEXTBL \n",
    "WHERE \"Payload_Mass\" = (SELECT MAX(\"Payload_Mass\") FROM SPACEXTBL);\n",
    "\"\"\"\n",
    "df1 = pd.read_sql_query(query1, conn)\n",
    "print(df1.to_string(index=False))\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9\n",
    "\n",
    "\n",
    "##### List the records which will display the month names, failure landing_outcomes in drone ship ,booster versions, launch_site for the months in year 2015.\n",
    "\n",
    "**Note: SQLLite does not support monthnames. So you need to use  substr(Date, 6,2) as month to get the months and substr(Date,0,5)='2015' for year.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 9: Month names, failure landing outcomes in drone ship, booster versions, launch_site for 2015\n",
      "====================================================================================================\n",
      "  Month      Landing_Outcome Booster_Version Launch_Site\n",
      "January Failure (drone ship)   F9 v1.1 B1012 CCAFS LC-40\n",
      "  April Failure (drone ship)   F9 v1.1 B1015 CCAFS LC-40\n",
      "\n",
      "=== Count of drone ship failure landings by month in 2015 ===\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DatetimeIndex' object has no attribute 'dt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Show a count by month\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Count of drone ship failure landings by month in 2015 ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m month_counts \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMonth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_counts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmonth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m month, count \u001b[38;5;129;01min\u001b[39;00m month_counts\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failure(s)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/series.py:3951\u001b[0m, in \u001b[0;36mSeries.sort_index\u001b[0;34m(self, axis, level, ascending, inplace, kind, na_position, sort_remaining, ignore_index, key)\u001b[0m\n\u001b[1;32m   3818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msort_index\u001b[39m(\n\u001b[1;32m   3819\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3820\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3829\u001b[0m     key: IndexKeyFunc \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3830\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3831\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3832\u001b[0m \u001b[38;5;124;03m    Sort Series by index labels.\u001b[39;00m\n\u001b[1;32m   3833\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3948\u001b[0m \u001b[38;5;124;03m    dtype: int64\u001b[39;00m\n\u001b[1;32m   3949\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3951\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3952\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3954\u001b[0m \u001b[43m        \u001b[49m\u001b[43mascending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mascending\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3955\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3958\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort_remaining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort_remaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3961\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/generic.py:5164\u001b[0m, in \u001b[0;36mNDFrame.sort_index\u001b[0;34m(self, axis, level, ascending, inplace, kind, na_position, sort_remaining, ignore_index, key)\u001b[0m\n\u001b[1;32m   5160\u001b[0m ascending \u001b[38;5;241m=\u001b[39m validate_ascending(ascending)\n\u001b[1;32m   5162\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m-> 5164\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[43mget_indexer_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mascending\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_position\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_remaining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\n\u001b[1;32m   5166\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inplace:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/sorting.py:90\u001b[0m, in \u001b[0;36mget_indexer_indexer\u001b[0;34m(target, level, ascending, kind, na_position, sort_remaining, key)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03mHelper method that return the indexer according to input parameters for\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03mthe sort_index method of DataFrame and Series.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    The indexer for the new index.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any], Index, Series]\", variable has\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# type \"Index\")\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[43mensure_key_mapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m     91\u001b[0m target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39m_sort_levels_monotonic()\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/sorting.py:574\u001b[0m, in \u001b[0;36mensure_key_mapped\u001b[0;34m(values, key, levels)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, ABCMultiIndex):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ensure_key_mapped_multiindex(values, key, level\u001b[38;5;241m=\u001b[39mlevels)\n\u001b[0;32m--> 574\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mkey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(values):\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-provided `key` function must not change the shape of the array.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[27], line 40\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Show a count by month\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Count of drone ship failure landings by month in 2015 ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m month_counts \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonth\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39msort_index(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[38;5;241m.\u001b[39mmonth)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m month, count \u001b[38;5;129;01min\u001b[39;00m month_counts\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failure(s)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DatetimeIndex' object has no attribute 'dt'"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('my_data1.db')\n",
    "\n",
    "# Clean version for Task 9\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    CASE substr(\"Date\", 6, 2)\n",
    "        WHEN '01' THEN 'January'\n",
    "        WHEN '02' THEN 'February'\n",
    "        WHEN '03' THEN 'March'\n",
    "        WHEN '04' THEN 'April'\n",
    "        WHEN '05' THEN 'May'\n",
    "        WHEN '06' THEN 'June'\n",
    "        WHEN '07' THEN 'July'\n",
    "        WHEN '08' THEN 'August'\n",
    "        WHEN '09' THEN 'September'\n",
    "        WHEN '10' THEN 'October'\n",
    "        WHEN '11' THEN 'November'\n",
    "        WHEN '12' THEN 'December'\n",
    "    END as \"Month\",\n",
    "    \"Landing_Outcome\",\n",
    "    \"Booster_Version\",\n",
    "    \"Launch_Site\"\n",
    "FROM SPACEXTBL \n",
    "WHERE substr(\"Date\", 1, 4) = '2015'\n",
    "  AND \"Landing_Outcome\" LIKE '%drone%'\n",
    "  AND (\"Landing_Outcome\" LIKE '%Fail%' OR \"Landing_Outcome\" LIKE '%fail%')\n",
    "ORDER BY substr(\"Date\", 6, 2);\n",
    "\"\"\"\n",
    "\n",
    "print(\"Task 9: Month names, failure landing outcomes in drone ship, booster versions, launch_site for 2015\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "if not df.empty:\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    # Show a count by month\n",
    "    print(f\"\\n=== Count of drone ship failure landings by month in 2015 ===\")\n",
    "    month_counts = df['Month'].value_counts().sort_index(key=lambda x: pd.to_datetime(x, format='%B').dt.month)\n",
    "    for month, count in month_counts.items():\n",
    "        print(f\"{month}: {count} failure(s)\")\n",
    "else:\n",
    "    print(\"No records found matching the criteria.\")\n",
    "    \n",
    "    # Try a broader search\n",
    "    print(\"\\nTrying broader search for drone ship outcomes in 2015...\")\n",
    "    broader_query = \"\"\"\n",
    "    SELECT \n",
    "        CASE substr(\"Date\", 6, 2)\n",
    "            WHEN '01' THEN 'January'\n",
    "            WHEN '02' THEN 'February'\n",
    "            WHEN '03' THEN 'March'\n",
    "            WHEN '04' THEN 'April'\n",
    "            WHEN '05' THEN 'May'\n",
    "            WHEN '06' THEN 'June'\n",
    "            WHEN '07' THEN 'July'\n",
    "            WHEN '08' THEN 'August'\n",
    "            WHEN '09' THEN 'September'\n",
    "            WHEN '10' THEN 'October'\n",
    "            WHEN '11' THEN 'November'\n",
    "            WHEN '12' THEN 'December'\n",
    "        END as \"Month\",\n",
    "        \"Landing_Outcome\",\n",
    "        \"Booster_Version\",\n",
    "        \"Launch_Site\"\n",
    "    FROM SPACEXTBL \n",
    "    WHERE substr(\"Date\", 1, 4) = '2015'\n",
    "      AND (\"Landing_Outcome\" LIKE '%drone%' OR \"Landing_Outcome\" LIKE '%DS%' OR \"Landing_Outcome\" LIKE '%ship%')\n",
    "    ORDER BY substr(\"Date\", 6, 2), \"Landing_Outcome\";\n",
    "    \"\"\"\n",
    "    \n",
    "    broader_df = pd.read_sql_query(broader_query, conn)\n",
    "    if not broader_df.empty:\n",
    "        print(f\"\\nFound {len(broader_df)} drone ship outcomes in 2015 (all types):\")\n",
    "        print(broader_df.to_string(index=False))\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### Rank the count of landing outcomes (such as Failure (drone ship) or Success (ground pad)) between the date 2010-06-04 and 2017-03-20, in descending order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 10: Count of landing outcomes between 2010-06-04 and 2017-03-20\n",
      "====================================================================================================\n",
      " Rank        Landing_Outcome  Outcome_Count\n",
      "    1             No attempt             10\n",
      "    2   Failure (drone ship)              5\n",
      "    3   Success (drone ship)              5\n",
      "    4     Controlled (ocean)              3\n",
      "    5   Success (ground pad)              3\n",
      "    6    Failure (parachute)              2\n",
      "    7   Uncontrolled (ocean)              2\n",
      "    8 Precluded (drone ship)              1\n",
      "\n",
      "=== Summary ===\n",
      "Total different landing outcomes: 8\n",
      "Total landings in period: 31\n",
      "\n",
      "=== Specific Outcome Examples ===\n",
      "Failure (drone ship): 5 occurrences (Rank 2)\n",
      "Failure (parachute): 2 occurrences (Rank 6)\n",
      "Success (drone ship): 5 occurrences (Rank 3)\n",
      "Success (ground pad): 3 occurrences (Rank 5)\n",
      "Success (drone ship): 5 occurrences (Rank 3)\n",
      "Success (ground pad): 3 occurrences (Rank 5)\n",
      "Failure (drone ship): 5 occurrences (Rank 2)\n",
      "Failure (parachute): 2 occurrences (Rank 6)\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect('my_data1.db')\n",
    "\n",
    "# Alternative without window functions\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    \"Landing_Outcome\",\n",
    "    COUNT(*) as Outcome_Count\n",
    "FROM SPACEXTBL \n",
    "WHERE \"Landing_Outcome\" IS NOT NULL\n",
    "  AND \"Date\" >= '2010-06-04' \n",
    "  AND \"Date\" <= '2017-03-20'\n",
    "GROUP BY \"Landing_Outcome\"\n",
    "ORDER BY Outcome_Count DESC, \"Landing_Outcome\";\n",
    "\"\"\"\n",
    "\n",
    "print(\"Task 10: Count of landing outcomes between 2010-06-04 and 2017-03-20\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "if not df.empty:\n",
    "    # Add rank manually in Python\n",
    "    df['Rank'] = range(1, len(df) + 1)\n",
    "    \n",
    "    # Reorder columns\n",
    "    df = df[['Rank', 'Landing_Outcome', 'Outcome_Count']]\n",
    "    \n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    # Show summary\n",
    "    print(f\"\\n=== Summary ===\")\n",
    "    print(f\"Total different landing outcomes: {len(df)}\")\n",
    "    print(f\"Total landings in period: {df['Outcome_Count'].sum()}\")\n",
    "    \n",
    "    # Show examples of specific outcomes mentioned in task\n",
    "    print(f\"\\n=== Specific Outcome Examples ===\")\n",
    "    specific_outcomes = ['Failure (drone ship)', 'Success (ground pad)', 'Success (drone ship)', 'Failure (ground pad)']\n",
    "    for outcome in specific_outcomes:\n",
    "        matches = df[df['Landing_Outcome'].str.contains(outcome.replace('(', '\\(').replace(')', '\\)'), regex=False)]\n",
    "        if not matches.empty:\n",
    "            for _, row in matches.iterrows():\n",
    "                print(f\"{row['Landing_Outcome']}: {row['Outcome_Count']} occurrences (Rank {row['Rank']})\")\n",
    "        else:\n",
    "            # Try partial match\n",
    "            partial_matches = df[df['Landing_Outcome'].str.contains(outcome.split(' ')[0], case=False, na=False)]\n",
    "            if not partial_matches.empty:\n",
    "                for _, row in partial_matches.iterrows():\n",
    "                    print(f\"{row['Landing_Outcome']}: {row['Outcome_Count']} occurrences (Rank {row['Rank']})\")\n",
    "    \n",
    "else:\n",
    "    print(\"No landing outcomes found in the specified date range.\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference Links\n",
    "\n",
    "* <a href =\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Labs_Coursera_V5/labs/Lab%20-%20String%20Patterns%20-%20Sorting%20-%20Grouping/instructional-labs.md.html?origin=www.coursera.org\">Hands-on Lab : String Patterns, Sorting and Grouping</a>  \n",
    "\n",
    "*  <a  href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Labs_Coursera_V5/labs/Lab%20-%20Built-in%20functions%20/Hands-on_Lab__Built-in_Functions.md.html?origin=www.coursera.org\">Hands-on Lab: Built-in functions</a>\n",
    "\n",
    "*  <a  href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Labs_Coursera_V5/labs/Lab%20-%20Sub-queries%20and%20Nested%20SELECTs%20/instructional-labs.md.html?origin=www.coursera.org\">Hands-on Lab : Sub-queries and Nested SELECT Statements</a>\n",
    "\n",
    "*   <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Module%205/DB0201EN-Week3-1-3-SQLmagic.ipynb\">Hands-on Tutorial: Accessing Databases with SQL magic</a>\n",
    "\n",
    "*  <a href= \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Module%205/DB0201EN-Week3-1-4-Analyzing.ipynb\">Hands-on Lab: Analyzing a real World Data Set</a>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author(s)\n",
    "\n",
    "<h4> Lakshmi Holla </h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Contributors\n",
    "\n",
    "<h4> Rav Ahuja </h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "## Change log\n",
    "| Date | Version | Changed by | Change Description |\n",
    "|------|--------|--------|---------|\n",
    "| 2024-07-10 | 1.1 |Anita Verma | Changed Version|\n",
    "| 2021-07-09 | 0.2 |Lakshmi Holla | Changes made in magic sql|\n",
    "| 2021-05-20 | 0.1 |Lakshmi Holla | Created Initial Version |\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h3 align=\"center\"> © IBM Corporation 2021. All rights reserved. <h3/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "12df46c3b0654f639da96fac3e05f156ee105e47e0c79adacb1892bc327713de"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
